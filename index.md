## Introduction

Over the past few years, generative machine learning and machine creativity have continued grow and attract a wider audience to machine learning. Generative models enable new types of media creation across images, music, and text - including recent advances such as sketch-rnn and the Universal Music Translation Network.  This one-day workshop broadly explores issues in the applications of machine learning to creativity and design. We will look at **algorithms for generation and creation** of new media and new designs, engaging researchers building the next generation of generative models (GANs, RL, etc). We investigate **the social and cultural impact** of these new models, engaging researchers from HCI/UX communities and those using machine learning to develop new creative tools. In addition to covering the technical advances, we also address the ethical concerns ranging from the use of biased datasets to building tools for better “DeepFakes”. Finally, we’ll hear from some of the artists and musicians who are adopting machine learning including deep learning and reinforcement learning as part of their own artistic process.  We aim to balance the technical issues and challenges of applying the latest generative models to creativity and design with philosophical and cultural issues that surround this area of research. 

The goal of this workshop is to bring together researchers and creative practitioners interested in advancing art and music generation to present new work, foster collaborations and build networks. 

<center>
<img src="https://cdn.rawgit.com/nips2017creativity/nips2017creativity.github.io/c947e344/assets/nips_logo.svg" width="90%"/>
</center>

## Keynote Speakers

Kenneth Stanley, University of Central Florida

David Ha, Google Brain

Allison Parrish, NYU ITP

Yaroslav Ganin, DeepMind

Yaniv Taigman, Facebook AI Research

<!-- TODO: add links to personal pages, as well as job titles (to match the layout from last year) -->

## Important Dates

28 October 2018: Submission date for papers and art

9 November 2018: Acceptance notification for papers

19 November 2018: Acceptance notification for art

28 November 2018:  Deadline for final copy of accepted papers

3–8 December 2018: NIPS Conference

8 December 2018: Workshop

## How to Participate

We invite participation in the form of papers and/or artwork.

### To Submit a Paper

We invite participants to submit 2-page papers in the NIPS camera-ready format (with author names visible), to be submitted to: `nips2018creativity@gmail.com`

In the subject line of your email, please put:

`NIPS Workshop: [Paper title]`

Topics may include (but are not limited to):
- Presentation of new machine learning techniques for generating art, music, or other creative outputs using, for instance, reinforcement learning, generative adversarial networks, novelty search and evaluation, etc
- Quantitative or qualitative evaluation of machine learning techniques for creative work and design 
- Tools or techniques to improve usability or usefulness of machine learning for creative practitioners
- Descriptions, reflections, or case studies on the use of machine learning in the creation of a new art or design work
- Information-theoretic views of creativity
- Aesthetic, philosophical, social, ethical and cultural considerations surrounding the use of machine learning in creative practice

On the submission page, you may also indicate whether you would like to present a demo of your work during the workshop (if applicable).

Papers will be reviewed by committee members, and accepted authors will present at the workshop in the form of a short talk, poster, and/or demo. At least one author of each accepted paper must register for and attend the workshop. Accepted papers will appear on the workshop website.

References and any supplementary materials provided do not count as part of the 2-page limit. However, it will be the reviewers' discretion to read the supplementary materials.

### To Submit Artwork

We welcome submission of artwork that has been created using machine learning (autonomously or with humans). We invite art in any medium, including but not limited to sound and music, image, video, dance, text, physical objects, food, etc… We will be able to accommodate work submitted in one of the following formats:
- Video 
- Audio (maximum 2 channel)
- Still image
- Website
- Other types of submissions (e.g., physical artefacts, performances, text, …) should be documented using one or more of the above formats. For instance, you might submit a video of a machine-learning-generated dance piece or a website documenting a text generation piece.

On this submission [page](https://docs.google.com/forms/d/1vYZT4_53qcWOLMr7XQ2KGUoeabkoOh164RTpH7lcyds), you will also be asked for a short text description of your work and a description of how machine learning was used in its creation.

Art submissions will be reviewed by committee members.





We will host an online gallery of accepted art submissions on the workshop website. While we will do our best to show a number of art pieces at the workshop itself, we will most likely not have access to adequate equipment and space to support a substantial exhibit. We may invite creators of accepted artwork to participate in the form of a short talk, poster, and/or demo.

Artists submitting work are encouraged though not required to attend in person. 

## Contact

If you have any questions, please contact us at `nips2018creativity@gmail.com`

Workshop website: [https://nips2018creativity.github.io](https://nips2018 creativity.github.io)

## Schedule

| Time    | Event  |
|---------|--------|
| 8:30 AM | Welcome and Introduction  |
| 8:45 AM | Invited Talk<br/>*Kenneth Stanley* |
| 9:15 AM | Invited Talk<br/>*Yaroslav Ganin* |
| 9:45 AM | Invited Talk<br/>*David Ha* |
| 10:15 AM | AI art gallery overview<br/>*Luba Elliott* |
| 10:30 AM | Art / Coffee Break |
| 11:00 AM | Invited Talk<br/>*Yaniv Taigman* |
| 11:30 AM | Performing Structured Improvisations with Pre-existing Generative Musical Models<br/>*Pablo Samuel Castro* |
| 11:45 AM | Legend of Wrong Mountain: Full Generation of Traditional Chinese Opera Using Multiple Machine Learning Algorithms<br/>*Lingdon Huang, Giada Sun, Zheng Jiang* |
| 12:00 PM | Lunch |
| 1:30 PM | Poster Session 1<br/>*Evan Casey, Colin A Raffel, Jonathan Simon, Billy Li, Rob Saunders, Petra Gemeinboeck, Eunsu Kang, Songwei Ge, Curtis "Fjord" Hawthorne, Anna Huang, Ting-Wei Su, Eric Chu, Memo Akten, Sonam Damani, Khyatti Gupta, Dilpreet Singh, Patrick Hutchings* |
| 2:30 PM | Invited Talk<br/>*Allison Parrish* |
| 3:00 PM | Art / Coffee Break |
| 3:30 PM | TimbreTron: A WaveNet(CycleGAN(CQT(Audio))) Pipeline for Musical Timbre Transfer<br/>*Sheldon Huang, Cem Anil, Xuchan Bao* |
| 3:45 PM | Infilling Piano performances<br/>*Daphne Ippolito* |
| 4:00 PM | Improvised Robotic Design with Found Objects<br/>*Azumi Maekawa* |
| 4:15 PM | SpaceSheets: Interactive Latent Space Exploration through a Spreadsheet Interface<br/>*Tom White* |
| 4:30 PM | 	Runway: Adding artificial intelligence capabilities to design and creative platforms<br/>*Cristobal Valenzuela, Anastasis Germanidis, Alejandro Matamala* |
| 4:45 PM | Open Discussion |
| 5:15 PM | AI art show<br/>*Ziv Epstein, Violet Chaney, Alex Champandard, Gene Kogan, Josh Davis* |
| 5:15 PM | Poster Session 2<br/>*Katy Gero, Aven Zhou, Simiao Yu, Zhengyan Gao, Chris Donahue, Billy Li, Taegyun Kwon, Patrick Hutchings, Charles Martin, Eunsu Kang, Asanobu Kitamoto, Zheng Jiang, Giada Sun, Philipp Schmitt, Maria Attarian, Alex Lamb, Tarin Clanuwat, Mauro Martino, Holly Grimm, Nikolay Jetchev* |

## Accepted Papers

Coming soon!

## Organisers

[Luba Elliott](https://twitter.com/elluba), AI Curator

[Sander Dieleman](https://twitter.com/sedielem), DeepMind

[Rebecca Fiebrink](https://twitter.com/RebeccaFiebrink), Goldsmiths University of London

[Adam Roberts](https://twitter.com/ada_rob),  Magenta, Google Brain

[Jesse Engel](https://twitter.com/jesseengel), Magenta, Google Brain

[Tom White](https://twitter.com/dribnet), Victoria University of Wellington
